# app/src/main/resources/application.yml

spring:
  application:
    name: journey-stitching
  profiles:
    active: dev

  kafka:
    # Common Kafka settings (overridden per profile if needed)
    consumer:
      enable-auto-commit: false
      auto-offset-reset: earliest
      # If you want batch consumption, set to true and adjust your listener accordingly
      # properties:
      #   max.poll.records: 200
    listener:
      # This sets container concurrency when using ConcurrentKafkaListenerContainerFactory
      concurrency: 6
    producer:
      # defaults are fine for String->String; add acks/retries if you produce to DLQ
      acks: all
      retries: 5

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,loggers
  endpoint:
    health:
      show-details: when_authorized

logging:
  level:
    root: INFO
    org.springframework.kafka: INFO
    org.apache.kafka: WARN
    co.elastic.clients: WARN
    com.abc.journey: DEBUG

# App-specific settings for ES and index names
app:
  elastic:
    host: localhost
    port: 9200
    scheme: http
    index:
      events-prefix: events     # daily index name will be events-YYYY.MM.DD
      journeys: journeys-v1
      ckmap: ckmap
      redirects: redirects

---
spring:
  config:
    activate:
      on-profile: docker
  kafka:
    bootstrap-servers: kafka:9092
  # In docker profile, point ES to the compose service name
app:
  elastic:
    host: es01
    port: 9200
    scheme: http

---
spring:
  config:
    activate:
      on-profile: dev
  kafka:
    bootstrap-servers: localhost:9092
